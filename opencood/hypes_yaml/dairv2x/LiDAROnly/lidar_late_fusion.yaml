name: DairV2X_lidar_late_heter_fusion
yaml_parser: "load_general_params"

# --- Dataset paths (ABSOLUTE) ---
data_dir: "/data3/my_dair_v2x/cooperative-vehicle-infrastructure"
root_dir: "/data3/my_dair_v2x/cooperative-vehicle-infrastructure/train.json"
validate_dir: "/data3/my_dair_v2x/cooperative-vehicle-infrastructure/val.json"
test_dir: "/data3/my_dair_v2x/cooperative-vehicle-infrastructure/val.json"

# --- Training ---
train_params:
  batch_size: &batch_size 4          # per-GPU; tune based on VRAM
  epoches: 20
  eval_freq: 2
  save_freq: 2
  max_cav: 5

# --- Scene / inputs ---
comm_range: 100
input_source: ['lidar']
label_type: 'lidar'
num_class: &num_class 3
cav_lidar_range: &cav_lidar [-140.8, -40, -3, 140.8, 40, 1]
dataset_mode: 'v2v'

heter:
  assignment_path: null
  ego_modality: &ego_modality "m1"
  mapping_dict:
    m1: m1
    m2: m1
  modality_setting:
    m1:
      sensor_type: &sensor_type_m1 'lidar'
      core_method: &core_method_m1 "point_pillar"
      preprocess:
        core_method: 'SpVoxelPreprocessor'
        args:
          voxel_size: &voxel_size [0.4, 0.4, 4]
          max_points_per_voxel: 32
          max_voxel_train: 32000
          max_voxel_test: 70000
        cav_lidar_range: *cav_lidar

# --- Fusion --- 
fusion:
  core_method: 'lateheter'
  dataset: 'dairv2x'
  args:
    proj_first: false
    grid_conf: None
    data_aug_conf: None

# --- Data augmentation (applied at world level) ---
data_augment:
  - NAME: random_world_flip
    ALONG_AXIS_LIST: ['x']
  - NAME: random_world_rotation
    WORLD_ROT_ANGLE: [-0.78539816, 0.78539816]
  - NAME: random_world_scaling
    WORLD_SCALE_RANGE: [0.95, 1.05]

# --- Preprocess (global defaults; per-modality overrides above) ---
preprocess:
  core_method: 'SpVoxelPreprocessor'
  args:
    voxel_size: [0.4, 0.4, 4]
    max_points_per_voxel: 32
    max_voxel_train: 32000
    max_voxel_test: 70000
  cav_lidar_range: *cav_lidar
  num_class: *num_class
  anchor_generator_config: &anchor_generator_config
    - 'class_name': 'vehicle'
      'anchor_sizes': [ [ 3.9, 1.6, 1.56 ] ]
      'anchor_rotations': [ 0, 1.57 ]
      'anchor_bottom_heights': [ -1.78 ]
      'align_center': True
      'feature_map_stride': 2
      'matched_threshold': 0.6
      'unmatched_threshold': 0.45
    - 'class_name': 'pedestrian'
      'anchor_sizes': [ [ 0.8, 0.6, 1.73 ] ]
      'anchor_rotations': [ 0, 1.57 ]
      'anchor_bottom_heights': [ -0.6 ]
      'align_center': True
      'feature_map_stride': 2
      'matched_threshold': 0.5
      'unmatched_threshold': 0.35
    - 'class_name': 'truck'
      'anchor_sizes': [ [ 8, 3, 3 ] ]
      'anchor_rotations': [ 0, 1.57 ]
      'anchor_bottom_heights': [ -1.78 ]
      'align_center': True
      'feature_map_stride': 2
      'matched_threshold': 0.6
      'unmatched_threshold': 0.45

postprocess:
  core_method: 'VoxelPostprocessor'
  gt_range: *cav_lidar
  anchor_args:
    cav_lidar_range: *cav_lidar
    l: 3.9
    w: 1.6
    h: 1.56
    r: &anchor_yaw [0, 90]
    feature_stride: 2
    num: &anchor_num 2
    anchor_generator_config: *anchor_generator_config
  target_args:
    pos_threshold: 0.6
    neg_threshold: 0.45
    score_threshold: 0.2
  order: 'hwl'
  max_num: 150
  nms_thresh: 0.15
  dir_args: &dir_args
    dir_offset: 0.7853
    num_bins: 2
    anchor_yaw: *anchor_yaw

# --- Model (PointPillars encoder + AttFuse) ---
model:
  core_method: heter_model_late
  args:
    ego_modality: *ego_modality
    lidar_range: *cav_lidar

    m1:
      core_method: *core_method_m1
      sensor_type: *sensor_type_m1

      encoder_args:
        voxel_size: *voxel_size
        lidar_range: *cav_lidar
        pillar_vfe:
          use_norm: true
          with_distance: false
          use_absolute_xyz: true
          num_filters: [64]
        point_pillar_scatter:
          num_features: 64

      backbone_args:
        layer_nums: [3]
        layer_strides: [2]
        num_filters: [64]
  
      aligner_args:
        core_method: identity

      layers_args: 
        layer_nums: [3, 5, 8]
        layer_strides: [2, 2, 2]
        num_filters: [64, 128, 256]
        upsample_strides: [1, 2, 4]
        num_upsample_filter: [128, 128, 128]

      shrink_header: 
        kernal_size: [ 3 ]
        stride: [ 1 ]
        padding: [ 1 ]
        dim: [ 256 ]
        input_dim: 384 # 128 * 3

      head_args:
        in_head: 256

    anchor_number: *anchor_num
    dir_args: *dir_args

# --- Loss / Optim / LR ---
loss:
  core_method: point_pillar_depth_loss
  args:
    pos_cls_weight: 2.0
    cls:  { type: 'SigmoidFocalLoss', alpha: 0.25, gamma: 2.0, weight: 1.0 }
    reg:  { type: 'WeightedSmoothL1Loss', sigma: 3.0, codewise: true, weight: 2.0 }
    dir:  { type: 'WeightedSoftmaxClassificationLoss', weight: 0.2, args: *dir_args }
    depth: { weight: 1.0 }

optimizer:
  core_method: Adam
  lr: 0.002
  args: { eps: 1e-10, weight_decay: 1e-4 }

lr_scheduler:
  core_method: multistep
  gamma: 0.1
  step_size: [10, 25]
